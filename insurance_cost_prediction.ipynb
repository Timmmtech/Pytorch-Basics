{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJ+83QcyFPaCz44IMavMyO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Timmmtech/Pytorch-Basics/blob/main/insurance_cost_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insurance cost prediction using linear regression\n",
        "In this project, we're going to use information like a person's age, sex, BMI, no. of children and smoking habit to predict the price of yearly medical bills. This kind of model is useful for insurance companies to determine the yearly insurance premium for a person. The dataset for this problem is taken from: https://www.kaggle.com/mirichoi0218/insurance\n",
        "\n",
        "We will create a model with the following steps:\n",
        "\n",
        "Download and explore the dataset\n",
        "Prepare the dataset for training\n",
        "Create a linear regression model\n",
        "Train the model to fit the data\n",
        "Make predictions using the trained model"
      ],
      "metadata": {
        "id": "u7Pb3l5NjIr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jovian --quiet\n",
        "\n",
        "import torch\n",
        "import jovian\n",
        "\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#Some styling\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "pd.pandas.set_option('display.max_columns', None)\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "IJxEAinajW1a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Download the dataset\n",
        "DATASET_URL = \"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\"\n",
        "DATA_FILENAME = \"insurance.csv\"\n",
        "download_url(DATASET_URL, '.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Uj-eJDAjsvm",
        "outputId": "139e41a8-34ed-453e-a140-b9d926a4566d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 54.3k/54.3k [00:00<00:00, 23.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.read_csv(DATA_FILENAME)\n",
        "dataframe.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MGVBM6Vpk1mm",
        "outputId": "d5131b37-e947-4767-c7d7-1e42392984ef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17d7f6f9-4090-498d-a1d9-ccbe1ba8fb54\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17d7f6f9-4090-498d-a1d9-ccbe1ba8fb54')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17d7f6f9-4090-498d-a1d9-ccbe1ba8fb54 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17d7f6f9-4090-498d-a1d9-ccbe1ba8fb54');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataframe",
              "summary": "{\n  \"name\": \"dataframe\",\n  \"rows\": 1338,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 18,\n        \"max\": 64,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          21,\n          45,\n          36\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"male\",\n          \"female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.098186911679017,\n        \"min\": 15.96,\n        \"max\": 53.13,\n        \"num_unique_values\": 548,\n        \"samples\": [\n          23.18,\n          26.885\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"children\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"no\",\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"region\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"southeast\",\n          \"northeast\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"charges\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12110.011236693994,\n        \"min\": 1121.8739,\n        \"max\": 63770.42801,\n        \"num_unique_values\": 1337,\n        \"samples\": [\n          8688.85885,\n          5708.867\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlSQeucAlKJ-",
        "outputId": "4f28c51d-5c1b-4804-ece6-c21dfd2ca4ac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1338, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q: How many rows does the dataset have?"
      ],
      "metadata": {
        "id": "Kmincz0slbW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_rows = dataframe.shape[0]\n",
        "print(num_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39QWt5CLlhFx",
        "outputId": "48fd9ce8-cab8-4ce3-f750-a97934e7cd13"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q: How many columns does the dataset have"
      ],
      "metadata": {
        "id": "LG5cJdtuluer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = dataframe.shape[1]\n",
        "print(num_cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xTfFPT2lyYk",
        "outputId": "6cf7513d-0159-444a-b938-426c9c65485f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q: What are the column titles of the input variables?"
      ],
      "metadata": {
        "id": "dOmgLJYPmpUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_cols = dataframe.columns[:-1]\n",
        "input_cols"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjgtiQurm1VR",
        "outputId": "78d5ab67-eebd-4ef8-db8e-81710799df85"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'sex', 'bmi', 'children', 'smoker', 'region'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q: Which of the input columns are non-numeric or categorial variables ?"
      ],
      "metadata": {
        "id": "j_zmFyeunMIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = ['sex', 'smoker', 'region']\n",
        "print(categorical_cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzsd9i7mnjpx",
        "outputId": "430bc6ef-d20e-48e9-8683-e43495d96479"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sex', 'smoker', 'region']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q: What are the column titles of output/target variable(s)?"
      ],
      "metadata": {
        "id": "70f3U9snnvnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_cols = ['charges']"
      ],
      "metadata": {
        "id": "gJ4LFNbRnzE3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the dataset for training"
      ],
      "metadata": {
        "id": "Y-WP4xcQoOsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Convert Pandas df to a Pytorch tensors for training\n",
        "def dataframe_to_arrays(dataframe):\n",
        "     # Make a copy of the original dataframe\n",
        "     dataframe1 = dataframe.copy(deep=True)\n",
        "     # Convert non-numeric categorical columns to numbers\n",
        "     for col in categorical_cols:\n",
        "         dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
        "     # Extract input & outupts as numpy arrays\n",
        "     inputs_array = dataframe1[input_cols].to_numpy()\n",
        "     targets_array = dataframe1[output_cols].to_numpy()\n",
        "     return inputs_array, targets_array"
      ],
      "metadata": {
        "id": "HjuwIr_coTTn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_array, targets_array = dataframe_to_arrays(dataframe)\n",
        "inputs_array.shape, targets_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpZYHCC9pcTI",
        "outputId": "ac9c1cc7-e7f3-47d8-958d-3f4fd4125000"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1338, 6), (1338, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Q: Convert the numpy arrays inputs_array and targets_array into PyTorch tensors. Make sure that the data type is torch.float32."
      ],
      "metadata": {
        "id": "9k9P8TcmrJNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.from_numpy(inputs_array).type(torch.float32)\n",
        "targets = torch.from_numpy(targets_array).type(torch.float32)"
      ],
      "metadata": {
        "id": "80RUJ0oYrRbP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.dtype, targets.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Msi2Zf6AsABl",
        "outputId": "1dc7ae19-ae51-45ca-faaf-610e26722e20"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## create tensor dataset\n",
        "dataset = TensorDataset(inputs, targets)"
      ],
      "metadata": {
        "id": "uI_QhUxRsIYi"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q: Pick a number between 0.1 and 0.2 to determine the fraction of data that will be used for creating the validation set. Then use random_split to create training & validation datasets."
      ],
      "metadata": {
        "id": "sTr_Va2jsRM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_percent = 0.2 # between 0.1 and 0.2\n",
        "val_size = int(num_rows * val_percent)\n",
        "train_size = num_rows - val_size\n",
        "\n",
        "\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size]) # Use the random_split function to split dataset into 2 parts of the desired length"
      ],
      "metadata": {
        "id": "uQyPhnJjtkSA"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q: Pick a batch size for the data loader."
      ],
      "metadata": {
        "id": "bhzgqrT8t3Pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32"
      ],
      "metadata": {
        "id": "CkWV852Gt58v"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size)"
      ],
      "metadata": {
        "id": "9fTcVKlIuFIh"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## check if batch data and others are working perfectly fine\n",
        "for xb, yb in train_loader:\n",
        "     print(\"inputs:\", xb)\n",
        "     print(\"targets:\", yb)\n",
        "     break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLR1_O9VuMpS",
        "outputId": "932f460a-550e-4d26-f59f-e2003d50180e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs: tensor([[19.0000,  0.0000, 25.7450,  1.0000,  0.0000,  1.0000],\n",
            "        [43.0000,  1.0000, 30.1000,  1.0000,  0.0000,  3.0000],\n",
            "        [35.0000,  1.0000, 24.1300,  1.0000,  0.0000,  1.0000],\n",
            "        [57.0000,  0.0000, 29.8100,  0.0000,  1.0000,  2.0000],\n",
            "        [52.0000,  0.0000, 31.7300,  2.0000,  0.0000,  1.0000],\n",
            "        [53.0000,  0.0000, 26.7000,  2.0000,  0.0000,  3.0000],\n",
            "        [32.0000,  0.0000, 20.5200,  0.0000,  0.0000,  0.0000],\n",
            "        [18.0000,  0.0000, 28.2150,  0.0000,  0.0000,  0.0000],\n",
            "        [30.0000,  1.0000, 27.6450,  1.0000,  0.0000,  0.0000],\n",
            "        [59.0000,  0.0000, 36.7650,  1.0000,  1.0000,  0.0000],\n",
            "        [35.0000,  0.0000, 43.3400,  2.0000,  0.0000,  2.0000],\n",
            "        [20.0000,  1.0000, 22.0000,  1.0000,  0.0000,  3.0000],\n",
            "        [41.0000,  1.0000, 28.8000,  1.0000,  0.0000,  3.0000],\n",
            "        [60.0000,  1.0000, 28.9000,  0.0000,  0.0000,  3.0000],\n",
            "        [57.0000,  1.0000, 34.0100,  0.0000,  0.0000,  1.0000],\n",
            "        [52.0000,  0.0000, 18.3350,  0.0000,  0.0000,  1.0000],\n",
            "        [31.0000,  1.0000, 20.4000,  0.0000,  0.0000,  3.0000],\n",
            "        [63.0000,  0.0000, 27.7400,  0.0000,  1.0000,  0.0000],\n",
            "        [61.0000,  0.0000, 36.3850,  1.0000,  1.0000,  0.0000],\n",
            "        [37.0000,  1.0000, 34.2000,  1.0000,  1.0000,  0.0000],\n",
            "        [22.0000,  0.0000, 21.2800,  3.0000,  0.0000,  1.0000],\n",
            "        [47.0000,  0.0000, 33.3450,  0.0000,  0.0000,  0.0000],\n",
            "        [44.0000,  0.0000, 25.0000,  1.0000,  0.0000,  3.0000],\n",
            "        [38.0000,  1.0000, 27.8350,  2.0000,  0.0000,  1.0000],\n",
            "        [19.0000,  0.0000, 23.4000,  2.0000,  0.0000,  3.0000],\n",
            "        [36.0000,  1.0000, 35.2000,  1.0000,  1.0000,  2.0000],\n",
            "        [26.0000,  1.0000, 35.4200,  0.0000,  0.0000,  2.0000],\n",
            "        [46.0000,  1.0000, 24.7950,  3.0000,  0.0000,  0.0000],\n",
            "        [35.0000,  0.0000, 35.8600,  2.0000,  0.0000,  2.0000],\n",
            "        [64.0000,  1.0000, 34.5000,  0.0000,  0.0000,  3.0000],\n",
            "        [25.0000,  1.0000, 24.1300,  0.0000,  1.0000,  1.0000],\n",
            "        [52.0000,  1.0000, 47.7400,  1.0000,  0.0000,  2.0000]])\n",
            "targets: tensor([[ 2710.8286],\n",
            "        [ 6849.0259],\n",
            "        [ 5125.2158],\n",
            "        [27533.9121],\n",
            "        [11187.6562],\n",
            "        [11150.7803],\n",
            "        [ 4544.2349],\n",
            "        [ 2200.8308],\n",
            "        [ 4237.1265],\n",
            "        [47896.7930],\n",
            "        [ 5846.9175],\n",
            "        [ 1964.7800],\n",
            "        [ 6282.2349],\n",
            "        [12146.9707],\n",
            "        [11356.6611],\n",
            "        [ 9991.0381],\n",
            "        [ 3260.1990],\n",
            "        [29523.1660],\n",
            "        [48517.5625],\n",
            "        [39047.2852],\n",
            "        [ 4296.2710],\n",
            "        [20878.7852],\n",
            "        [ 7623.5181],\n",
            "        [ 6455.8628],\n",
            "        [ 2913.5691],\n",
            "        [38709.1758],\n",
            "        [ 2322.6218],\n",
            "        [ 9500.5732],\n",
            "        [ 5836.5205],\n",
            "        [13822.8027],\n",
            "        [15817.9854],\n",
            "        [ 9748.9102]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Linear Regression Model"
      ],
      "metadata": {
        "id": "kaYqSatsulHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = len(input_cols)\n",
        "output_size = len(output_cols)"
      ],
      "metadata": {
        "id": "Fr3i5iKyuniK"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InsuranceModel(nn.Module):\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "      self.linear = nn.Linear(input_size, output_size)\n",
        "\n",
        "  def forward(self, xb):\n",
        "      out = self.linear(xb)\n",
        "      return out\n",
        "\n",
        "  def training_step(self, batch):\n",
        "    inputs, targets = batch\n",
        "    # Generate predictions\n",
        "    out = self(inputs)\n",
        "    # Calculate loss\n",
        "    loss = F.mse_loss(out, targets)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch):\n",
        "      inputs, targets = batch\n",
        "      out = self(inputs)\n",
        "      loss = F.mse_loss(out, targets)\n",
        "      return {'val_loss': loss.detach()}\n",
        "\n",
        "  def validation_epoch_end(self, outputs):\n",
        "      batch_losses = [x['val_loss'] for x in outputs]\n",
        "      epoch_loss = torch.stack(batch_losses).mean()\n",
        "      return {'val_loss': epoch_loss.item()}\n",
        "\n",
        "  def epoch_end(self, epoch, result, num_epochs):\n",
        "      # Print result every 20th epoch\n",
        "      if (epoch+1) % 100 == 0 or epoch == num_epochs-1:\n",
        "          print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "4Q-stPaiw-KQ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## creating a model using InsuranceModel class\n",
        "model = InsuranceModel()"
      ],
      "metadata": {
        "id": "zWwno_lK0AgA"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## check out weight and biases of the model\n",
        "list(model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRKwNneP0JpX",
        "outputId": "7f8cc2f7-efa6-4c69-b05d-5fe1017a72e4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.0421, -0.1904, -0.0428, -0.1493,  0.0132,  0.3404]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.3395], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model to fit the data"
      ],
      "metadata": {
        "id": "vWjfUnZ90brM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate (model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "      # Training Phase\n",
        "         for batch in train_loader:\n",
        "             loss = model.training_step(batch)\n",
        "             loss.backward()\n",
        "             optimizer.step()\n",
        "             optimizer.zero_grad()\n",
        "             # Validation Phase\n",
        "             result = evaluate(model, val_loader)\n",
        "             model.epoch_end(epoch, result, epochs)\n",
        "             history.append(result)\n",
        "    return history"
      ],
      "metadata": {
        "id": "NaHaTiNo0iYu"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q: Use the evaluate function to calculate the loss on the validation set before training."
      ],
      "metadata": {
        "id": "ArwG40kV4TK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = evaluate(model, val_loader) # Use the the evaluate function\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4pazhPm4Yve",
        "outputId": "6b75915d-9ebb-4ff2-d9d0-b3f70712c36b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'val_loss': 327191552.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q: Train the model 4-5 times with different learning rates & for different number of epochs."
      ],
      "metadata": {
        "id": "nYlsXMxR4oA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = InsuranceModel()"
      ],
      "metadata": {
        "id": "eb3lscdt4rL3"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2000\n",
        "lr = 1e-4\n",
        "history1 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCjiOPPU4uJA",
        "outputId": "3231d765-a442-46b9-9640-d14e18006088"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100], val_loss: 128164896.0000\n",
            "Epoch [100], val_loss: 129131976.0000\n",
            "Epoch [100], val_loss: 128748832.0000\n",
            "Epoch [100], val_loss: 127451960.0000\n",
            "Epoch [100], val_loss: 126559760.0000\n",
            "Epoch [100], val_loss: 126888160.0000\n",
            "Epoch [100], val_loss: 126496424.0000\n",
            "Epoch [100], val_loss: 128489160.0000\n",
            "Epoch [100], val_loss: 127684296.0000\n",
            "Epoch [100], val_loss: 126941736.0000\n",
            "Epoch [100], val_loss: 126415032.0000\n",
            "Epoch [100], val_loss: 127697152.0000\n",
            "Epoch [100], val_loss: 130667480.0000\n",
            "Epoch [100], val_loss: 126620248.0000\n",
            "Epoch [100], val_loss: 128090864.0000\n",
            "Epoch [100], val_loss: 126376160.0000\n",
            "Epoch [100], val_loss: 126374744.0000\n",
            "Epoch [100], val_loss: 135075728.0000\n",
            "Epoch [100], val_loss: 129035304.0000\n",
            "Epoch [100], val_loss: 126792872.0000\n",
            "Epoch [100], val_loss: 128696928.0000\n",
            "Epoch [100], val_loss: 128871240.0000\n",
            "Epoch [100], val_loss: 127240376.0000\n",
            "Epoch [100], val_loss: 126513264.0000\n",
            "Epoch [100], val_loss: 130435360.0000\n",
            "Epoch [100], val_loss: 126763024.0000\n",
            "Epoch [100], val_loss: 128720184.0000\n",
            "Epoch [100], val_loss: 126764944.0000\n",
            "Epoch [100], val_loss: 126496584.0000\n",
            "Epoch [100], val_loss: 127063848.0000\n",
            "Epoch [100], val_loss: 129433312.0000\n",
            "Epoch [100], val_loss: 129104528.0000\n",
            "Epoch [100], val_loss: 127803424.0000\n",
            "Epoch [100], val_loss: 126444672.0000\n",
            "Epoch [200], val_loss: 110362584.0000\n",
            "Epoch [200], val_loss: 111139808.0000\n",
            "Epoch [200], val_loss: 112499144.0000\n",
            "Epoch [200], val_loss: 110403872.0000\n",
            "Epoch [200], val_loss: 111327424.0000\n",
            "Epoch [200], val_loss: 110764984.0000\n",
            "Epoch [200], val_loss: 110326512.0000\n",
            "Epoch [200], val_loss: 112702224.0000\n",
            "Epoch [200], val_loss: 110906776.0000\n",
            "Epoch [200], val_loss: 110268912.0000\n",
            "Epoch [200], val_loss: 110364872.0000\n",
            "Epoch [200], val_loss: 112280360.0000\n",
            "Epoch [200], val_loss: 110559072.0000\n",
            "Epoch [200], val_loss: 110195728.0000\n",
            "Epoch [200], val_loss: 110059304.0000\n",
            "Epoch [200], val_loss: 110258624.0000\n",
            "Epoch [200], val_loss: 110165344.0000\n",
            "Epoch [200], val_loss: 112252776.0000\n",
            "Epoch [200], val_loss: 119991280.0000\n",
            "Epoch [200], val_loss: 113244328.0000\n",
            "Epoch [200], val_loss: 111124032.0000\n",
            "Epoch [200], val_loss: 110514496.0000\n",
            "Epoch [200], val_loss: 110174320.0000\n",
            "Epoch [200], val_loss: 110165496.0000\n",
            "Epoch [200], val_loss: 110681064.0000\n",
            "Epoch [200], val_loss: 113514752.0000\n",
            "Epoch [200], val_loss: 111653088.0000\n",
            "Epoch [200], val_loss: 112689504.0000\n",
            "Epoch [200], val_loss: 110812280.0000\n",
            "Epoch [200], val_loss: 110238312.0000\n",
            "Epoch [200], val_loss: 111116352.0000\n",
            "Epoch [200], val_loss: 110262584.0000\n",
            "Epoch [200], val_loss: 110671832.0000\n",
            "Epoch [200], val_loss: 112499848.0000\n",
            "Epoch [300], val_loss: 97437312.0000\n",
            "Epoch [300], val_loss: 97224840.0000\n",
            "Epoch [300], val_loss: 98393424.0000\n",
            "Epoch [300], val_loss: 98828488.0000\n",
            "Epoch [300], val_loss: 97906368.0000\n",
            "Epoch [300], val_loss: 99075536.0000\n",
            "Epoch [300], val_loss: 103264288.0000\n",
            "Epoch [300], val_loss: 100459904.0000\n",
            "Epoch [300], val_loss: 101975336.0000\n",
            "Epoch [300], val_loss: 103214632.0000\n",
            "Epoch [300], val_loss: 99913400.0000\n",
            "Epoch [300], val_loss: 97614600.0000\n",
            "Epoch [300], val_loss: 98984920.0000\n",
            "Epoch [300], val_loss: 97075872.0000\n",
            "Epoch [300], val_loss: 97777984.0000\n",
            "Epoch [300], val_loss: 97435328.0000\n",
            "Epoch [300], val_loss: 97317344.0000\n",
            "Epoch [300], val_loss: 101564192.0000\n",
            "Epoch [300], val_loss: 97129288.0000\n",
            "Epoch [300], val_loss: 97384496.0000\n",
            "Epoch [300], val_loss: 98499024.0000\n",
            "Epoch [300], val_loss: 109772312.0000\n",
            "Epoch [300], val_loss: 99282648.0000\n",
            "Epoch [300], val_loss: 98911528.0000\n",
            "Epoch [300], val_loss: 97257720.0000\n",
            "Epoch [300], val_loss: 98832448.0000\n",
            "Epoch [300], val_loss: 97843744.0000\n",
            "Epoch [300], val_loss: 97327144.0000\n",
            "Epoch [300], val_loss: 97048224.0000\n",
            "Epoch [300], val_loss: 97263424.0000\n",
            "Epoch [300], val_loss: 97783624.0000\n",
            "Epoch [300], val_loss: 97022176.0000\n",
            "Epoch [300], val_loss: 99141368.0000\n",
            "Epoch [300], val_loss: 96979240.0000\n",
            "Epoch [400], val_loss: 87680152.0000\n",
            "Epoch [400], val_loss: 90580976.0000\n",
            "Epoch [400], val_loss: 86617200.0000\n",
            "Epoch [400], val_loss: 87024296.0000\n",
            "Epoch [400], val_loss: 86710064.0000\n",
            "Epoch [400], val_loss: 86798304.0000\n",
            "Epoch [400], val_loss: 87876720.0000\n",
            "Epoch [400], val_loss: 86555720.0000\n",
            "Epoch [400], val_loss: 86937264.0000\n",
            "Epoch [400], val_loss: 87556032.0000\n",
            "Epoch [400], val_loss: 86884568.0000\n",
            "Epoch [400], val_loss: 86926832.0000\n",
            "Epoch [400], val_loss: 87069136.0000\n",
            "Epoch [400], val_loss: 91479712.0000\n",
            "Epoch [400], val_loss: 88619584.0000\n",
            "Epoch [400], val_loss: 88176040.0000\n",
            "Epoch [400], val_loss: 86768840.0000\n",
            "Epoch [400], val_loss: 87557424.0000\n",
            "Epoch [400], val_loss: 86606536.0000\n",
            "Epoch [400], val_loss: 86956272.0000\n",
            "Epoch [400], val_loss: 88937744.0000\n",
            "Epoch [400], val_loss: 88117664.0000\n",
            "Epoch [400], val_loss: 89057368.0000\n",
            "Epoch [400], val_loss: 87124144.0000\n",
            "Epoch [400], val_loss: 86701672.0000\n",
            "Epoch [400], val_loss: 86498032.0000\n",
            "Epoch [400], val_loss: 86961960.0000\n",
            "Epoch [400], val_loss: 86802568.0000\n",
            "Epoch [400], val_loss: 89564728.0000\n",
            "Epoch [400], val_loss: 87235216.0000\n",
            "Epoch [400], val_loss: 90240152.0000\n",
            "Epoch [400], val_loss: 90690136.0000\n",
            "Epoch [400], val_loss: 91374008.0000\n",
            "Epoch [400], val_loss: 86426112.0000\n",
            "Epoch [500], val_loss: 79518304.0000\n",
            "Epoch [500], val_loss: 79581432.0000\n",
            "Epoch [500], val_loss: 80528608.0000\n",
            "Epoch [500], val_loss: 79199320.0000\n",
            "Epoch [500], val_loss: 77932640.0000\n",
            "Epoch [500], val_loss: 78180080.0000\n",
            "Epoch [500], val_loss: 77889672.0000\n",
            "Epoch [500], val_loss: 78053688.0000\n",
            "Epoch [500], val_loss: 78392208.0000\n",
            "Epoch [500], val_loss: 80953224.0000\n",
            "Epoch [500], val_loss: 80821416.0000\n",
            "Epoch [500], val_loss: 81560320.0000\n",
            "Epoch [500], val_loss: 79233160.0000\n",
            "Epoch [500], val_loss: 81509792.0000\n",
            "Epoch [500], val_loss: 80278968.0000\n",
            "Epoch [500], val_loss: 78995016.0000\n",
            "Epoch [500], val_loss: 78148192.0000\n",
            "Epoch [500], val_loss: 78742880.0000\n",
            "Epoch [500], val_loss: 78015872.0000\n",
            "Epoch [500], val_loss: 78833368.0000\n",
            "Epoch [500], val_loss: 80912680.0000\n",
            "Epoch [500], val_loss: 77930136.0000\n",
            "Epoch [500], val_loss: 79073752.0000\n",
            "Epoch [500], val_loss: 77984552.0000\n",
            "Epoch [500], val_loss: 78134120.0000\n",
            "Epoch [500], val_loss: 78685408.0000\n",
            "Epoch [500], val_loss: 79244208.0000\n",
            "Epoch [500], val_loss: 77982472.0000\n",
            "Epoch [500], val_loss: 78478408.0000\n",
            "Epoch [500], val_loss: 78238024.0000\n",
            "Epoch [500], val_loss: 78625320.0000\n",
            "Epoch [500], val_loss: 82713928.0000\n",
            "Epoch [500], val_loss: 78478624.0000\n",
            "Epoch [500], val_loss: 78313568.0000\n",
            "Epoch [600], val_loss: 73953032.0000\n",
            "Epoch [600], val_loss: 71216256.0000\n",
            "Epoch [600], val_loss: 71403416.0000\n",
            "Epoch [600], val_loss: 74001168.0000\n",
            "Epoch [600], val_loss: 72650344.0000\n",
            "Epoch [600], val_loss: 73408440.0000\n",
            "Epoch [600], val_loss: 72549448.0000\n",
            "Epoch [600], val_loss: 71154600.0000\n",
            "Epoch [600], val_loss: 70952728.0000\n",
            "Epoch [600], val_loss: 71518208.0000\n",
            "Epoch [600], val_loss: 71308328.0000\n",
            "Epoch [600], val_loss: 73618800.0000\n",
            "Epoch [600], val_loss: 71739856.0000\n",
            "Epoch [600], val_loss: 72619048.0000\n",
            "Epoch [600], val_loss: 72808472.0000\n",
            "Epoch [600], val_loss: 71173216.0000\n",
            "Epoch [600], val_loss: 71553456.0000\n",
            "Epoch [600], val_loss: 71429416.0000\n",
            "Epoch [600], val_loss: 71126408.0000\n",
            "Epoch [600], val_loss: 70938616.0000\n",
            "Epoch [600], val_loss: 71345720.0000\n",
            "Epoch [600], val_loss: 70968416.0000\n",
            "Epoch [600], val_loss: 70807032.0000\n",
            "Epoch [600], val_loss: 71130064.0000\n",
            "Epoch [600], val_loss: 71302816.0000\n",
            "Epoch [600], val_loss: 71037560.0000\n",
            "Epoch [600], val_loss: 71218344.0000\n",
            "Epoch [600], val_loss: 72541280.0000\n",
            "Epoch [600], val_loss: 75550864.0000\n",
            "Epoch [600], val_loss: 72920408.0000\n",
            "Epoch [600], val_loss: 71462112.0000\n",
            "Epoch [600], val_loss: 71114664.0000\n",
            "Epoch [600], val_loss: 71083616.0000\n",
            "Epoch [600], val_loss: 74327104.0000\n",
            "Epoch [700], val_loss: 65694548.0000\n",
            "Epoch [700], val_loss: 66755912.0000\n",
            "Epoch [700], val_loss: 65568812.0000\n",
            "Epoch [700], val_loss: 65881464.0000\n",
            "Epoch [700], val_loss: 66351792.0000\n",
            "Epoch [700], val_loss: 67662816.0000\n",
            "Epoch [700], val_loss: 72899392.0000\n",
            "Epoch [700], val_loss: 69229376.0000\n",
            "Epoch [700], val_loss: 65838116.0000\n",
            "Epoch [700], val_loss: 65410924.0000\n",
            "Epoch [700], val_loss: 65250672.0000\n",
            "Epoch [700], val_loss: 65958344.0000\n",
            "Epoch [700], val_loss: 67213472.0000\n",
            "Epoch [700], val_loss: 70022232.0000\n",
            "Epoch [700], val_loss: 67556752.0000\n",
            "Epoch [700], val_loss: 66042340.0000\n",
            "Epoch [700], val_loss: 67075920.0000\n",
            "Epoch [700], val_loss: 65506964.0000\n",
            "Epoch [700], val_loss: 65956240.0000\n",
            "Epoch [700], val_loss: 66072560.0000\n",
            "Epoch [700], val_loss: 65263040.0000\n",
            "Epoch [700], val_loss: 65524912.0000\n",
            "Epoch [700], val_loss: 66234512.0000\n",
            "Epoch [700], val_loss: 65495332.0000\n",
            "Epoch [700], val_loss: 65240976.0000\n",
            "Epoch [700], val_loss: 65427504.0000\n",
            "Epoch [700], val_loss: 66076432.0000\n",
            "Epoch [700], val_loss: 65584952.0000\n",
            "Epoch [700], val_loss: 65276552.0000\n",
            "Epoch [700], val_loss: 65345628.0000\n",
            "Epoch [700], val_loss: 65261292.0000\n",
            "Epoch [700], val_loss: 65714028.0000\n",
            "Epoch [700], val_loss: 65193372.0000\n",
            "Epoch [700], val_loss: 65199344.0000\n",
            "Epoch [800], val_loss: 62715116.0000\n",
            "Epoch [800], val_loss: 71298616.0000\n",
            "Epoch [800], val_loss: 64340976.0000\n",
            "Epoch [800], val_loss: 61934608.0000\n",
            "Epoch [800], val_loss: 60701120.0000\n",
            "Epoch [800], val_loss: 60528348.0000\n",
            "Epoch [800], val_loss: 60578808.0000\n",
            "Epoch [800], val_loss: 60636372.0000\n",
            "Epoch [800], val_loss: 60638272.0000\n",
            "Epoch [800], val_loss: 60794312.0000\n",
            "Epoch [800], val_loss: 60940580.0000\n",
            "Epoch [800], val_loss: 60559852.0000\n",
            "Epoch [800], val_loss: 60613576.0000\n",
            "Epoch [800], val_loss: 61552752.0000\n",
            "Epoch [800], val_loss: 60617964.0000\n",
            "Epoch [800], val_loss: 61936080.0000\n",
            "Epoch [800], val_loss: 60709596.0000\n",
            "Epoch [800], val_loss: 60567012.0000\n",
            "Epoch [800], val_loss: 63372152.0000\n",
            "Epoch [800], val_loss: 61129296.0000\n",
            "Epoch [800], val_loss: 60862712.0000\n",
            "Epoch [800], val_loss: 60560276.0000\n",
            "Epoch [800], val_loss: 61617380.0000\n",
            "Epoch [800], val_loss: 66813968.0000\n",
            "Epoch [800], val_loss: 67221280.0000\n",
            "Epoch [800], val_loss: 64765440.0000\n",
            "Epoch [800], val_loss: 63587920.0000\n",
            "Epoch [800], val_loss: 60756464.0000\n",
            "Epoch [800], val_loss: 61105144.0000\n",
            "Epoch [800], val_loss: 60609840.0000\n",
            "Epoch [800], val_loss: 60523520.0000\n",
            "Epoch [800], val_loss: 60770640.0000\n",
            "Epoch [800], val_loss: 61143792.0000\n",
            "Epoch [800], val_loss: 64795884.0000\n",
            "Epoch [900], val_loss: 56955284.0000\n",
            "Epoch [900], val_loss: 60495444.0000\n",
            "Epoch [900], val_loss: 57539788.0000\n",
            "Epoch [900], val_loss: 57726840.0000\n",
            "Epoch [900], val_loss: 62112428.0000\n",
            "Epoch [900], val_loss: 59651888.0000\n",
            "Epoch [900], val_loss: 62218260.0000\n",
            "Epoch [900], val_loss: 56776044.0000\n",
            "Epoch [900], val_loss: 56704512.0000\n",
            "Epoch [900], val_loss: 56945076.0000\n",
            "Epoch [900], val_loss: 56815540.0000\n",
            "Epoch [900], val_loss: 57766872.0000\n",
            "Epoch [900], val_loss: 56709064.0000\n",
            "Epoch [900], val_loss: 56713908.0000\n",
            "Epoch [900], val_loss: 56938020.0000\n",
            "Epoch [900], val_loss: 56645292.0000\n",
            "Epoch [900], val_loss: 57105568.0000\n",
            "Epoch [900], val_loss: 56847292.0000\n",
            "Epoch [900], val_loss: 59572888.0000\n",
            "Epoch [900], val_loss: 57281604.0000\n",
            "Epoch [900], val_loss: 56755604.0000\n",
            "Epoch [900], val_loss: 56675592.0000\n",
            "Epoch [900], val_loss: 57757836.0000\n",
            "Epoch [900], val_loss: 57266384.0000\n",
            "Epoch [900], val_loss: 56680776.0000\n",
            "Epoch [900], val_loss: 58620188.0000\n",
            "Epoch [900], val_loss: 57569872.0000\n",
            "Epoch [900], val_loss: 56814932.0000\n",
            "Epoch [900], val_loss: 57164160.0000\n",
            "Epoch [900], val_loss: 56772368.0000\n",
            "Epoch [900], val_loss: 62812460.0000\n",
            "Epoch [900], val_loss: 58504300.0000\n",
            "Epoch [900], val_loss: 57396424.0000\n",
            "Epoch [900], val_loss: 57397892.0000\n",
            "Epoch [1000], val_loss: 58393660.0000\n",
            "Epoch [1000], val_loss: 57125816.0000\n",
            "Epoch [1000], val_loss: 59727360.0000\n",
            "Epoch [1000], val_loss: 55624292.0000\n",
            "Epoch [1000], val_loss: 54569324.0000\n",
            "Epoch [1000], val_loss: 53837268.0000\n",
            "Epoch [1000], val_loss: 53634832.0000\n",
            "Epoch [1000], val_loss: 55522872.0000\n",
            "Epoch [1000], val_loss: 57362836.0000\n",
            "Epoch [1000], val_loss: 56453744.0000\n",
            "Epoch [1000], val_loss: 53933908.0000\n",
            "Epoch [1000], val_loss: 54155788.0000\n",
            "Epoch [1000], val_loss: 53498184.0000\n",
            "Epoch [1000], val_loss: 54111680.0000\n",
            "Epoch [1000], val_loss: 55241228.0000\n",
            "Epoch [1000], val_loss: 55626568.0000\n",
            "Epoch [1000], val_loss: 55045616.0000\n",
            "Epoch [1000], val_loss: 53536224.0000\n",
            "Epoch [1000], val_loss: 53606356.0000\n",
            "Epoch [1000], val_loss: 53584592.0000\n",
            "Epoch [1000], val_loss: 53580616.0000\n",
            "Epoch [1000], val_loss: 53990628.0000\n",
            "Epoch [1000], val_loss: 53651664.0000\n",
            "Epoch [1000], val_loss: 53923536.0000\n",
            "Epoch [1000], val_loss: 54375396.0000\n",
            "Epoch [1000], val_loss: 53557188.0000\n",
            "Epoch [1000], val_loss: 53651452.0000\n",
            "Epoch [1000], val_loss: 53549752.0000\n",
            "Epoch [1000], val_loss: 54388932.0000\n",
            "Epoch [1000], val_loss: 53555888.0000\n",
            "Epoch [1000], val_loss: 55423276.0000\n",
            "Epoch [1000], val_loss: 54514948.0000\n",
            "Epoch [1000], val_loss: 56281848.0000\n",
            "Epoch [1000], val_loss: 56988192.0000\n",
            "Epoch [1100], val_loss: 51011924.0000\n",
            "Epoch [1100], val_loss: 51286876.0000\n",
            "Epoch [1100], val_loss: 50978740.0000\n",
            "Epoch [1100], val_loss: 51096768.0000\n",
            "Epoch [1100], val_loss: 50986724.0000\n",
            "Epoch [1100], val_loss: 51350084.0000\n",
            "Epoch [1100], val_loss: 50932848.0000\n",
            "Epoch [1100], val_loss: 51552704.0000\n",
            "Epoch [1100], val_loss: 55858600.0000\n",
            "Epoch [1100], val_loss: 52228140.0000\n",
            "Epoch [1100], val_loss: 50814960.0000\n",
            "Epoch [1100], val_loss: 50881916.0000\n",
            "Epoch [1100], val_loss: 51205416.0000\n",
            "Epoch [1100], val_loss: 50898944.0000\n",
            "Epoch [1100], val_loss: 50890832.0000\n",
            "Epoch [1100], val_loss: 50919184.0000\n",
            "Epoch [1100], val_loss: 50869168.0000\n",
            "Epoch [1100], val_loss: 51223064.0000\n",
            "Epoch [1100], val_loss: 50884816.0000\n",
            "Epoch [1100], val_loss: 51775348.0000\n",
            "Epoch [1100], val_loss: 52527208.0000\n",
            "Epoch [1100], val_loss: 57002256.0000\n",
            "Epoch [1100], val_loss: 53943292.0000\n",
            "Epoch [1100], val_loss: 55266768.0000\n",
            "Epoch [1100], val_loss: 60207068.0000\n",
            "Epoch [1100], val_loss: 55944932.0000\n",
            "Epoch [1100], val_loss: 56307948.0000\n",
            "Epoch [1100], val_loss: 51770816.0000\n",
            "Epoch [1100], val_loss: 51019468.0000\n",
            "Epoch [1100], val_loss: 51986128.0000\n",
            "Epoch [1100], val_loss: 51049032.0000\n",
            "Epoch [1100], val_loss: 51199316.0000\n",
            "Epoch [1100], val_loss: 50978316.0000\n",
            "Epoch [1100], val_loss: 50970900.0000\n",
            "Epoch [1200], val_loss: 50502704.0000\n",
            "Epoch [1200], val_loss: 51703024.0000\n",
            "Epoch [1200], val_loss: 50643124.0000\n",
            "Epoch [1200], val_loss: 49622640.0000\n",
            "Epoch [1200], val_loss: 51207964.0000\n",
            "Epoch [1200], val_loss: 48971500.0000\n",
            "Epoch [1200], val_loss: 48746756.0000\n",
            "Epoch [1200], val_loss: 51124848.0000\n",
            "Epoch [1200], val_loss: 50019588.0000\n",
            "Epoch [1200], val_loss: 48869816.0000\n",
            "Epoch [1200], val_loss: 49692116.0000\n",
            "Epoch [1200], val_loss: 49078208.0000\n",
            "Epoch [1200], val_loss: 48789308.0000\n",
            "Epoch [1200], val_loss: 48791504.0000\n",
            "Epoch [1200], val_loss: 48879464.0000\n",
            "Epoch [1200], val_loss: 49106656.0000\n",
            "Epoch [1200], val_loss: 48807840.0000\n",
            "Epoch [1200], val_loss: 48946168.0000\n",
            "Epoch [1200], val_loss: 48775508.0000\n",
            "Epoch [1200], val_loss: 48834368.0000\n",
            "Epoch [1200], val_loss: 49200180.0000\n",
            "Epoch [1200], val_loss: 48792952.0000\n",
            "Epoch [1200], val_loss: 49000684.0000\n",
            "Epoch [1200], val_loss: 48932848.0000\n",
            "Epoch [1200], val_loss: 50567760.0000\n",
            "Epoch [1200], val_loss: 51628880.0000\n",
            "Epoch [1200], val_loss: 53724740.0000\n",
            "Epoch [1200], val_loss: 51422736.0000\n",
            "Epoch [1200], val_loss: 58469032.0000\n",
            "Epoch [1200], val_loss: 54471680.0000\n",
            "Epoch [1200], val_loss: 50305532.0000\n",
            "Epoch [1200], val_loss: 49740072.0000\n",
            "Epoch [1200], val_loss: 50373676.0000\n",
            "Epoch [1200], val_loss: 49016660.0000\n",
            "Epoch [1300], val_loss: 47165872.0000\n",
            "Epoch [1300], val_loss: 47057052.0000\n",
            "Epoch [1300], val_loss: 47065648.0000\n",
            "Epoch [1300], val_loss: 47153116.0000\n",
            "Epoch [1300], val_loss: 47131340.0000\n",
            "Epoch [1300], val_loss: 47105692.0000\n",
            "Epoch [1300], val_loss: 47122344.0000\n",
            "Epoch [1300], val_loss: 49299200.0000\n",
            "Epoch [1300], val_loss: 49026488.0000\n",
            "Epoch [1300], val_loss: 48402816.0000\n",
            "Epoch [1300], val_loss: 47682256.0000\n",
            "Epoch [1300], val_loss: 47244536.0000\n",
            "Epoch [1300], val_loss: 47768564.0000\n",
            "Epoch [1300], val_loss: 47103520.0000\n",
            "Epoch [1300], val_loss: 47962016.0000\n",
            "Epoch [1300], val_loss: 48721776.0000\n",
            "Epoch [1300], val_loss: 47498276.0000\n",
            "Epoch [1300], val_loss: 49028560.0000\n",
            "Epoch [1300], val_loss: 48429968.0000\n",
            "Epoch [1300], val_loss: 50532176.0000\n",
            "Epoch [1300], val_loss: 47136408.0000\n",
            "Epoch [1300], val_loss: 48099280.0000\n",
            "Epoch [1300], val_loss: 50692396.0000\n",
            "Epoch [1300], val_loss: 48000052.0000\n",
            "Epoch [1300], val_loss: 48079820.0000\n",
            "Epoch [1300], val_loss: 47605272.0000\n",
            "Epoch [1300], val_loss: 47822096.0000\n",
            "Epoch [1300], val_loss: 47752788.0000\n",
            "Epoch [1300], val_loss: 49056784.0000\n",
            "Epoch [1300], val_loss: 50704632.0000\n",
            "Epoch [1300], val_loss: 47082196.0000\n",
            "Epoch [1300], val_loss: 47117104.0000\n",
            "Epoch [1300], val_loss: 48462004.0000\n",
            "Epoch [1300], val_loss: 48821148.0000\n",
            "Epoch [1400], val_loss: 45718912.0000\n",
            "Epoch [1400], val_loss: 45539980.0000\n",
            "Epoch [1400], val_loss: 45533872.0000\n",
            "Epoch [1400], val_loss: 45538820.0000\n",
            "Epoch [1400], val_loss: 49872732.0000\n",
            "Epoch [1400], val_loss: 46087888.0000\n",
            "Epoch [1400], val_loss: 45615040.0000\n",
            "Epoch [1400], val_loss: 45999316.0000\n",
            "Epoch [1400], val_loss: 46071476.0000\n",
            "Epoch [1400], val_loss: 47593112.0000\n",
            "Epoch [1400], val_loss: 46189004.0000\n",
            "Epoch [1400], val_loss: 45570528.0000\n",
            "Epoch [1400], val_loss: 45587840.0000\n",
            "Epoch [1400], val_loss: 47139796.0000\n",
            "Epoch [1400], val_loss: 48538620.0000\n",
            "Epoch [1400], val_loss: 51808352.0000\n",
            "Epoch [1400], val_loss: 53466244.0000\n",
            "Epoch [1400], val_loss: 47971584.0000\n",
            "Epoch [1400], val_loss: 46510168.0000\n",
            "Epoch [1400], val_loss: 45685136.0000\n",
            "Epoch [1400], val_loss: 45649632.0000\n",
            "Epoch [1400], val_loss: 47851008.0000\n",
            "Epoch [1400], val_loss: 45624784.0000\n",
            "Epoch [1400], val_loss: 46456764.0000\n",
            "Epoch [1400], val_loss: 46683552.0000\n",
            "Epoch [1400], val_loss: 45993576.0000\n",
            "Epoch [1400], val_loss: 45632300.0000\n",
            "Epoch [1400], val_loss: 45705148.0000\n",
            "Epoch [1400], val_loss: 48538172.0000\n",
            "Epoch [1400], val_loss: 45651152.0000\n",
            "Epoch [1400], val_loss: 45747984.0000\n",
            "Epoch [1400], val_loss: 45581128.0000\n",
            "Epoch [1400], val_loss: 45851784.0000\n",
            "Epoch [1400], val_loss: 45799368.0000\n",
            "Epoch [1500], val_loss: 45712384.0000\n",
            "Epoch [1500], val_loss: 44626244.0000\n",
            "Epoch [1500], val_loss: 44844072.0000\n",
            "Epoch [1500], val_loss: 44288108.0000\n",
            "Epoch [1500], val_loss: 44474548.0000\n",
            "Epoch [1500], val_loss: 44301476.0000\n",
            "Epoch [1500], val_loss: 44264752.0000\n",
            "Epoch [1500], val_loss: 47594380.0000\n",
            "Epoch [1500], val_loss: 46209076.0000\n",
            "Epoch [1500], val_loss: 45839240.0000\n",
            "Epoch [1500], val_loss: 46319980.0000\n",
            "Epoch [1500], val_loss: 44436536.0000\n",
            "Epoch [1500], val_loss: 44929660.0000\n",
            "Epoch [1500], val_loss: 44708796.0000\n",
            "Epoch [1500], val_loss: 44217520.0000\n",
            "Epoch [1500], val_loss: 44247576.0000\n",
            "Epoch [1500], val_loss: 45992256.0000\n",
            "Epoch [1500], val_loss: 44739912.0000\n",
            "Epoch [1500], val_loss: 48897988.0000\n",
            "Epoch [1500], val_loss: 48939420.0000\n",
            "Epoch [1500], val_loss: 44611984.0000\n",
            "Epoch [1500], val_loss: 44251204.0000\n",
            "Epoch [1500], val_loss: 44254280.0000\n",
            "Epoch [1500], val_loss: 44254992.0000\n",
            "Epoch [1500], val_loss: 44885004.0000\n",
            "Epoch [1500], val_loss: 44660768.0000\n",
            "Epoch [1500], val_loss: 44499864.0000\n",
            "Epoch [1500], val_loss: 44266508.0000\n",
            "Epoch [1500], val_loss: 45044380.0000\n",
            "Epoch [1500], val_loss: 48638120.0000\n",
            "Epoch [1500], val_loss: 46844044.0000\n",
            "Epoch [1500], val_loss: 44734344.0000\n",
            "Epoch [1500], val_loss: 44424928.0000\n",
            "Epoch [1500], val_loss: 47848704.0000\n",
            "Epoch [1600], val_loss: 44050032.0000\n",
            "Epoch [1600], val_loss: 43737972.0000\n",
            "Epoch [1600], val_loss: 44352832.0000\n",
            "Epoch [1600], val_loss: 49215020.0000\n",
            "Epoch [1600], val_loss: 46235028.0000\n",
            "Epoch [1600], val_loss: 46407888.0000\n",
            "Epoch [1600], val_loss: 45910252.0000\n",
            "Epoch [1600], val_loss: 43279948.0000\n",
            "Epoch [1600], val_loss: 45912728.0000\n",
            "Epoch [1600], val_loss: 44700988.0000\n",
            "Epoch [1600], val_loss: 44622928.0000\n",
            "Epoch [1600], val_loss: 43780416.0000\n",
            "Epoch [1600], val_loss: 44098416.0000\n",
            "Epoch [1600], val_loss: 43913232.0000\n",
            "Epoch [1600], val_loss: 43278716.0000\n",
            "Epoch [1600], val_loss: 43272204.0000\n",
            "Epoch [1600], val_loss: 45762736.0000\n",
            "Epoch [1600], val_loss: 43481760.0000\n",
            "Epoch [1600], val_loss: 43330020.0000\n",
            "Epoch [1600], val_loss: 43407184.0000\n",
            "Epoch [1600], val_loss: 44914436.0000\n",
            "Epoch [1600], val_loss: 43589296.0000\n",
            "Epoch [1600], val_loss: 43818460.0000\n",
            "Epoch [1600], val_loss: 44594128.0000\n",
            "Epoch [1600], val_loss: 43971060.0000\n",
            "Epoch [1600], val_loss: 43294932.0000\n",
            "Epoch [1600], val_loss: 43666220.0000\n",
            "Epoch [1600], val_loss: 43893000.0000\n",
            "Epoch [1600], val_loss: 43334156.0000\n",
            "Epoch [1600], val_loss: 43262300.0000\n",
            "Epoch [1600], val_loss: 43849788.0000\n",
            "Epoch [1600], val_loss: 43282172.0000\n",
            "Epoch [1600], val_loss: 43808356.0000\n",
            "Epoch [1600], val_loss: 44119600.0000\n",
            "Epoch [1700], val_loss: 42449284.0000\n",
            "Epoch [1700], val_loss: 43176504.0000\n",
            "Epoch [1700], val_loss: 45070932.0000\n",
            "Epoch [1700], val_loss: 45864312.0000\n",
            "Epoch [1700], val_loss: 44521560.0000\n",
            "Epoch [1700], val_loss: 42327896.0000\n",
            "Epoch [1700], val_loss: 42722192.0000\n",
            "Epoch [1700], val_loss: 42308400.0000\n",
            "Epoch [1700], val_loss: 42348344.0000\n",
            "Epoch [1700], val_loss: 44365376.0000\n",
            "Epoch [1700], val_loss: 42552972.0000\n",
            "Epoch [1700], val_loss: 45811936.0000\n",
            "Epoch [1700], val_loss: 44638372.0000\n",
            "Epoch [1700], val_loss: 46477808.0000\n",
            "Epoch [1700], val_loss: 43656848.0000\n",
            "Epoch [1700], val_loss: 42390672.0000\n",
            "Epoch [1700], val_loss: 44536716.0000\n",
            "Epoch [1700], val_loss: 43205844.0000\n",
            "Epoch [1700], val_loss: 44048736.0000\n",
            "Epoch [1700], val_loss: 42905868.0000\n",
            "Epoch [1700], val_loss: 42565904.0000\n",
            "Epoch [1700], val_loss: 43213940.0000\n",
            "Epoch [1700], val_loss: 42507616.0000\n",
            "Epoch [1700], val_loss: 42352144.0000\n",
            "Epoch [1700], val_loss: 42537016.0000\n",
            "Epoch [1700], val_loss: 42683792.0000\n",
            "Epoch [1700], val_loss: 43578084.0000\n",
            "Epoch [1700], val_loss: 42802148.0000\n",
            "Epoch [1700], val_loss: 42477484.0000\n",
            "Epoch [1700], val_loss: 42387192.0000\n",
            "Epoch [1700], val_loss: 42545052.0000\n",
            "Epoch [1700], val_loss: 42341180.0000\n",
            "Epoch [1700], val_loss: 43942420.0000\n",
            "Epoch [1700], val_loss: 42472352.0000\n",
            "Epoch [1800], val_loss: 44895088.0000\n",
            "Epoch [1800], val_loss: 42145408.0000\n",
            "Epoch [1800], val_loss: 41814236.0000\n",
            "Epoch [1800], val_loss: 41643364.0000\n",
            "Epoch [1800], val_loss: 42051616.0000\n",
            "Epoch [1800], val_loss: 41678108.0000\n",
            "Epoch [1800], val_loss: 41754496.0000\n",
            "Epoch [1800], val_loss: 41629956.0000\n",
            "Epoch [1800], val_loss: 41824708.0000\n",
            "Epoch [1800], val_loss: 42532072.0000\n",
            "Epoch [1800], val_loss: 41808384.0000\n",
            "Epoch [1800], val_loss: 41630416.0000\n",
            "Epoch [1800], val_loss: 43889912.0000\n",
            "Epoch [1800], val_loss: 41802416.0000\n",
            "Epoch [1800], val_loss: 42322392.0000\n",
            "Epoch [1800], val_loss: 43246904.0000\n",
            "Epoch [1800], val_loss: 42848800.0000\n",
            "Epoch [1800], val_loss: 42886008.0000\n",
            "Epoch [1800], val_loss: 45179808.0000\n",
            "Epoch [1800], val_loss: 42840456.0000\n",
            "Epoch [1800], val_loss: 41828000.0000\n",
            "Epoch [1800], val_loss: 41600068.0000\n",
            "Epoch [1800], val_loss: 41643760.0000\n",
            "Epoch [1800], val_loss: 41688192.0000\n",
            "Epoch [1800], val_loss: 43841076.0000\n",
            "Epoch [1800], val_loss: 43643000.0000\n",
            "Epoch [1800], val_loss: 42663320.0000\n",
            "Epoch [1800], val_loss: 41637352.0000\n",
            "Epoch [1800], val_loss: 42388916.0000\n",
            "Epoch [1800], val_loss: 43200176.0000\n",
            "Epoch [1800], val_loss: 42753816.0000\n",
            "Epoch [1800], val_loss: 44392352.0000\n",
            "Epoch [1800], val_loss: 43181512.0000\n",
            "Epoch [1800], val_loss: 41780848.0000\n",
            "Epoch [1900], val_loss: 41172080.0000\n",
            "Epoch [1900], val_loss: 42379620.0000\n",
            "Epoch [1900], val_loss: 41032296.0000\n",
            "Epoch [1900], val_loss: 41205008.0000\n",
            "Epoch [1900], val_loss: 41207876.0000\n",
            "Epoch [1900], val_loss: 41111332.0000\n",
            "Epoch [1900], val_loss: 41017520.0000\n",
            "Epoch [1900], val_loss: 41349688.0000\n",
            "Epoch [1900], val_loss: 42907784.0000\n",
            "Epoch [1900], val_loss: 46943324.0000\n",
            "Epoch [1900], val_loss: 46975900.0000\n",
            "Epoch [1900], val_loss: 45031336.0000\n",
            "Epoch [1900], val_loss: 45197484.0000\n",
            "Epoch [1900], val_loss: 42929620.0000\n",
            "Epoch [1900], val_loss: 43017936.0000\n",
            "Epoch [1900], val_loss: 43584540.0000\n",
            "Epoch [1900], val_loss: 40967108.0000\n",
            "Epoch [1900], val_loss: 42089800.0000\n",
            "Epoch [1900], val_loss: 41092864.0000\n",
            "Epoch [1900], val_loss: 42097672.0000\n",
            "Epoch [1900], val_loss: 41732068.0000\n",
            "Epoch [1900], val_loss: 41038308.0000\n",
            "Epoch [1900], val_loss: 41304496.0000\n",
            "Epoch [1900], val_loss: 40990832.0000\n",
            "Epoch [1900], val_loss: 41048048.0000\n",
            "Epoch [1900], val_loss: 41275888.0000\n",
            "Epoch [1900], val_loss: 41084836.0000\n",
            "Epoch [1900], val_loss: 41007944.0000\n",
            "Epoch [1900], val_loss: 41487540.0000\n",
            "Epoch [1900], val_loss: 42823776.0000\n",
            "Epoch [1900], val_loss: 41820796.0000\n",
            "Epoch [1900], val_loss: 42055056.0000\n",
            "Epoch [1900], val_loss: 41009040.0000\n",
            "Epoch [1900], val_loss: 41013020.0000\n",
            "Epoch [2000], val_loss: 41123696.0000\n",
            "Epoch [2000], val_loss: 41892588.0000\n",
            "Epoch [2000], val_loss: 40694444.0000\n",
            "Epoch [2000], val_loss: 40501980.0000\n",
            "Epoch [2000], val_loss: 40533876.0000\n",
            "Epoch [2000], val_loss: 41362704.0000\n",
            "Epoch [2000], val_loss: 40775660.0000\n",
            "Epoch [2000], val_loss: 40403788.0000\n",
            "Epoch [2000], val_loss: 40444064.0000\n",
            "Epoch [2000], val_loss: 40612908.0000\n",
            "Epoch [2000], val_loss: 40503792.0000\n",
            "Epoch [2000], val_loss: 40454156.0000\n",
            "Epoch [2000], val_loss: 40838580.0000\n",
            "Epoch [2000], val_loss: 43097368.0000\n",
            "Epoch [2000], val_loss: 44184812.0000\n",
            "Epoch [2000], val_loss: 42252596.0000\n",
            "Epoch [2000], val_loss: 40480772.0000\n",
            "Epoch [2000], val_loss: 41241840.0000\n",
            "Epoch [2000], val_loss: 41523252.0000\n",
            "Epoch [2000], val_loss: 40711888.0000\n",
            "Epoch [2000], val_loss: 41087196.0000\n",
            "Epoch [2000], val_loss: 42480240.0000\n",
            "Epoch [2000], val_loss: 41278320.0000\n",
            "Epoch [2000], val_loss: 43518036.0000\n",
            "Epoch [2000], val_loss: 43160276.0000\n",
            "Epoch [2000], val_loss: 41851376.0000\n",
            "Epoch [2000], val_loss: 40662620.0000\n",
            "Epoch [2000], val_loss: 41729932.0000\n",
            "Epoch [2000], val_loss: 41546004.0000\n",
            "Epoch [2000], val_loss: 43761516.0000\n",
            "Epoch [2000], val_loss: 41510744.0000\n",
            "Epoch [2000], val_loss: 41114332.0000\n",
            "Epoch [2000], val_loss: 41248604.0000\n",
            "Epoch [2000], val_loss: 42159920.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "lr = 1e-4\n",
        "history2 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD-1gZV2GodB",
        "outputId": "b82f564b-281e-4bb6-a552-47cc3c04e874"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100], val_loss: 40958672.0000\n",
            "Epoch [100], val_loss: 40552200.0000\n",
            "Epoch [100], val_loss: 40108060.0000\n",
            "Epoch [100], val_loss: 41278384.0000\n",
            "Epoch [100], val_loss: 41091120.0000\n",
            "Epoch [100], val_loss: 43532304.0000\n",
            "Epoch [100], val_loss: 41445048.0000\n",
            "Epoch [100], val_loss: 41076384.0000\n",
            "Epoch [100], val_loss: 48601200.0000\n",
            "Epoch [100], val_loss: 42416884.0000\n",
            "Epoch [100], val_loss: 40659196.0000\n",
            "Epoch [100], val_loss: 40411832.0000\n",
            "Epoch [100], val_loss: 40900928.0000\n",
            "Epoch [100], val_loss: 40516008.0000\n",
            "Epoch [100], val_loss: 40092836.0000\n",
            "Epoch [100], val_loss: 40527636.0000\n",
            "Epoch [100], val_loss: 40742144.0000\n",
            "Epoch [100], val_loss: 41501696.0000\n",
            "Epoch [100], val_loss: 40263236.0000\n",
            "Epoch [100], val_loss: 40025604.0000\n",
            "Epoch [100], val_loss: 40748768.0000\n",
            "Epoch [100], val_loss: 40969980.0000\n",
            "Epoch [100], val_loss: 40375384.0000\n",
            "Epoch [100], val_loss: 40012088.0000\n",
            "Epoch [100], val_loss: 41584632.0000\n",
            "Epoch [100], val_loss: 41028904.0000\n",
            "Epoch [100], val_loss: 40088236.0000\n",
            "Epoch [100], val_loss: 40687780.0000\n",
            "Epoch [100], val_loss: 40422640.0000\n",
            "Epoch [100], val_loss: 40829840.0000\n",
            "Epoch [100], val_loss: 42138572.0000\n",
            "Epoch [100], val_loss: 41414108.0000\n",
            "Epoch [100], val_loss: 40305072.0000\n",
            "Epoch [100], val_loss: 42167536.0000\n",
            "Epoch [200], val_loss: 40787068.0000\n",
            "Epoch [200], val_loss: 40406656.0000\n",
            "Epoch [200], val_loss: 40570160.0000\n",
            "Epoch [200], val_loss: 44683476.0000\n",
            "Epoch [200], val_loss: 43068296.0000\n",
            "Epoch [200], val_loss: 43282956.0000\n",
            "Epoch [200], val_loss: 40214208.0000\n",
            "Epoch [200], val_loss: 39844964.0000\n",
            "Epoch [200], val_loss: 39527216.0000\n",
            "Epoch [200], val_loss: 40106160.0000\n",
            "Epoch [200], val_loss: 39828432.0000\n",
            "Epoch [200], val_loss: 40572080.0000\n",
            "Epoch [200], val_loss: 39663844.0000\n",
            "Epoch [200], val_loss: 41956260.0000\n",
            "Epoch [200], val_loss: 39589120.0000\n",
            "Epoch [200], val_loss: 43926864.0000\n",
            "Epoch [200], val_loss: 41282016.0000\n",
            "Epoch [200], val_loss: 40400060.0000\n",
            "Epoch [200], val_loss: 39823032.0000\n",
            "Epoch [200], val_loss: 40196728.0000\n",
            "Epoch [200], val_loss: 39926964.0000\n",
            "Epoch [200], val_loss: 39774308.0000\n",
            "Epoch [200], val_loss: 39973592.0000\n",
            "Epoch [200], val_loss: 39618668.0000\n",
            "Epoch [200], val_loss: 39527584.0000\n",
            "Epoch [200], val_loss: 39650716.0000\n",
            "Epoch [200], val_loss: 42259140.0000\n",
            "Epoch [200], val_loss: 40181176.0000\n",
            "Epoch [200], val_loss: 39500624.0000\n",
            "Epoch [200], val_loss: 39491692.0000\n",
            "Epoch [200], val_loss: 39510960.0000\n",
            "Epoch [200], val_loss: 39539588.0000\n",
            "Epoch [200], val_loss: 39616812.0000\n",
            "Epoch [200], val_loss: 40363216.0000\n",
            "Epoch [300], val_loss: 40093060.0000\n",
            "Epoch [300], val_loss: 40375944.0000\n",
            "Epoch [300], val_loss: 39717648.0000\n",
            "Epoch [300], val_loss: 40192624.0000\n",
            "Epoch [300], val_loss: 39284512.0000\n",
            "Epoch [300], val_loss: 39715980.0000\n",
            "Epoch [300], val_loss: 39231296.0000\n",
            "Epoch [300], val_loss: 39273244.0000\n",
            "Epoch [300], val_loss: 39242116.0000\n",
            "Epoch [300], val_loss: 39794276.0000\n",
            "Epoch [300], val_loss: 39342376.0000\n",
            "Epoch [300], val_loss: 40072416.0000\n",
            "Epoch [300], val_loss: 39945628.0000\n",
            "Epoch [300], val_loss: 42129888.0000\n",
            "Epoch [300], val_loss: 40307644.0000\n",
            "Epoch [300], val_loss: 39843848.0000\n",
            "Epoch [300], val_loss: 39302972.0000\n",
            "Epoch [300], val_loss: 40842812.0000\n",
            "Epoch [300], val_loss: 39216504.0000\n",
            "Epoch [300], val_loss: 39208284.0000\n",
            "Epoch [300], val_loss: 39670840.0000\n",
            "Epoch [300], val_loss: 39552696.0000\n",
            "Epoch [300], val_loss: 41374952.0000\n",
            "Epoch [300], val_loss: 39748944.0000\n",
            "Epoch [300], val_loss: 39973340.0000\n",
            "Epoch [300], val_loss: 39658012.0000\n",
            "Epoch [300], val_loss: 39845164.0000\n",
            "Epoch [300], val_loss: 41982920.0000\n",
            "Epoch [300], val_loss: 39449432.0000\n",
            "Epoch [300], val_loss: 40522456.0000\n",
            "Epoch [300], val_loss: 40306896.0000\n",
            "Epoch [300], val_loss: 42069272.0000\n",
            "Epoch [300], val_loss: 41537708.0000\n",
            "Epoch [300], val_loss: 39470800.0000\n",
            "Epoch [400], val_loss: 39749872.0000\n",
            "Epoch [400], val_loss: 39236116.0000\n",
            "Epoch [400], val_loss: 38849196.0000\n",
            "Epoch [400], val_loss: 39354940.0000\n",
            "Epoch [400], val_loss: 41228024.0000\n",
            "Epoch [400], val_loss: 42121056.0000\n",
            "Epoch [400], val_loss: 40326596.0000\n",
            "Epoch [400], val_loss: 41333404.0000\n",
            "Epoch [400], val_loss: 40086736.0000\n",
            "Epoch [400], val_loss: 39802324.0000\n",
            "Epoch [400], val_loss: 39436996.0000\n",
            "Epoch [400], val_loss: 39763424.0000\n",
            "Epoch [400], val_loss: 39770132.0000\n",
            "Epoch [400], val_loss: 39506712.0000\n",
            "Epoch [400], val_loss: 39055960.0000\n",
            "Epoch [400], val_loss: 38962384.0000\n",
            "Epoch [400], val_loss: 38939528.0000\n",
            "Epoch [400], val_loss: 38929756.0000\n",
            "Epoch [400], val_loss: 40242012.0000\n",
            "Epoch [400], val_loss: 43740340.0000\n",
            "Epoch [400], val_loss: 39957664.0000\n",
            "Epoch [400], val_loss: 39852596.0000\n",
            "Epoch [400], val_loss: 39906240.0000\n",
            "Epoch [400], val_loss: 39458400.0000\n",
            "Epoch [400], val_loss: 39020944.0000\n",
            "Epoch [400], val_loss: 39064568.0000\n",
            "Epoch [400], val_loss: 38987056.0000\n",
            "Epoch [400], val_loss: 38914192.0000\n",
            "Epoch [400], val_loss: 39215160.0000\n",
            "Epoch [400], val_loss: 40334736.0000\n",
            "Epoch [400], val_loss: 39486148.0000\n",
            "Epoch [400], val_loss: 40411620.0000\n",
            "Epoch [400], val_loss: 39352572.0000\n",
            "Epoch [400], val_loss: 40313092.0000\n",
            "Epoch [500], val_loss: 38649392.0000\n",
            "Epoch [500], val_loss: 38671000.0000\n",
            "Epoch [500], val_loss: 39620356.0000\n",
            "Epoch [500], val_loss: 38601852.0000\n",
            "Epoch [500], val_loss: 38612644.0000\n",
            "Epoch [500], val_loss: 38875172.0000\n",
            "Epoch [500], val_loss: 39532940.0000\n",
            "Epoch [500], val_loss: 38709544.0000\n",
            "Epoch [500], val_loss: 38704764.0000\n",
            "Epoch [500], val_loss: 41073952.0000\n",
            "Epoch [500], val_loss: 42571104.0000\n",
            "Epoch [500], val_loss: 38942128.0000\n",
            "Epoch [500], val_loss: 39731272.0000\n",
            "Epoch [500], val_loss: 38880052.0000\n",
            "Epoch [500], val_loss: 39728920.0000\n",
            "Epoch [500], val_loss: 45479868.0000\n",
            "Epoch [500], val_loss: 40971656.0000\n",
            "Epoch [500], val_loss: 41276072.0000\n",
            "Epoch [500], val_loss: 41849116.0000\n",
            "Epoch [500], val_loss: 39637160.0000\n",
            "Epoch [500], val_loss: 38981888.0000\n",
            "Epoch [500], val_loss: 38872272.0000\n",
            "Epoch [500], val_loss: 38957176.0000\n",
            "Epoch [500], val_loss: 38654004.0000\n",
            "Epoch [500], val_loss: 38861504.0000\n",
            "Epoch [500], val_loss: 40061072.0000\n",
            "Epoch [500], val_loss: 42064160.0000\n",
            "Epoch [500], val_loss: 40250404.0000\n",
            "Epoch [500], val_loss: 38911560.0000\n",
            "Epoch [500], val_loss: 38759508.0000\n",
            "Epoch [500], val_loss: 39615416.0000\n",
            "Epoch [500], val_loss: 39541648.0000\n",
            "Epoch [500], val_loss: 38684572.0000\n",
            "Epoch [500], val_loss: 39774864.0000\n",
            "Epoch [600], val_loss: 40027648.0000\n",
            "Epoch [600], val_loss: 39012832.0000\n",
            "Epoch [600], val_loss: 40550144.0000\n",
            "Epoch [600], val_loss: 39634524.0000\n",
            "Epoch [600], val_loss: 38411080.0000\n",
            "Epoch [600], val_loss: 38443480.0000\n",
            "Epoch [600], val_loss: 39613024.0000\n",
            "Epoch [600], val_loss: 40105128.0000\n",
            "Epoch [600], val_loss: 38551852.0000\n",
            "Epoch [600], val_loss: 38506044.0000\n",
            "Epoch [600], val_loss: 38485744.0000\n",
            "Epoch [600], val_loss: 39039056.0000\n",
            "Epoch [600], val_loss: 38373704.0000\n",
            "Epoch [600], val_loss: 39475796.0000\n",
            "Epoch [600], val_loss: 39301112.0000\n",
            "Epoch [600], val_loss: 39116792.0000\n",
            "Epoch [600], val_loss: 38618708.0000\n",
            "Epoch [600], val_loss: 38393836.0000\n",
            "Epoch [600], val_loss: 38934216.0000\n",
            "Epoch [600], val_loss: 44117752.0000\n",
            "Epoch [600], val_loss: 39362080.0000\n",
            "Epoch [600], val_loss: 39123792.0000\n",
            "Epoch [600], val_loss: 39434208.0000\n",
            "Epoch [600], val_loss: 39171088.0000\n",
            "Epoch [600], val_loss: 39080708.0000\n",
            "Epoch [600], val_loss: 38658736.0000\n",
            "Epoch [600], val_loss: 39985136.0000\n",
            "Epoch [600], val_loss: 38428824.0000\n",
            "Epoch [600], val_loss: 40194020.0000\n",
            "Epoch [600], val_loss: 42746272.0000\n",
            "Epoch [600], val_loss: 39048128.0000\n",
            "Epoch [600], val_loss: 40858576.0000\n",
            "Epoch [600], val_loss: 39406548.0000\n",
            "Epoch [600], val_loss: 40154452.0000\n",
            "Epoch [700], val_loss: 38564956.0000\n",
            "Epoch [700], val_loss: 40198580.0000\n",
            "Epoch [700], val_loss: 44381592.0000\n",
            "Epoch [700], val_loss: 44422592.0000\n",
            "Epoch [700], val_loss: 40155368.0000\n",
            "Epoch [700], val_loss: 42656008.0000\n",
            "Epoch [700], val_loss: 38773900.0000\n",
            "Epoch [700], val_loss: 38610464.0000\n",
            "Epoch [700], val_loss: 38362644.0000\n",
            "Epoch [700], val_loss: 39554108.0000\n",
            "Epoch [700], val_loss: 38840668.0000\n",
            "Epoch [700], val_loss: 38715184.0000\n",
            "Epoch [700], val_loss: 39698148.0000\n",
            "Epoch [700], val_loss: 40780408.0000\n",
            "Epoch [700], val_loss: 41393252.0000\n",
            "Epoch [700], val_loss: 39803808.0000\n",
            "Epoch [700], val_loss: 39655908.0000\n",
            "Epoch [700], val_loss: 39813840.0000\n",
            "Epoch [700], val_loss: 41774996.0000\n",
            "Epoch [700], val_loss: 38290688.0000\n",
            "Epoch [700], val_loss: 38254252.0000\n",
            "Epoch [700], val_loss: 38367540.0000\n",
            "Epoch [700], val_loss: 39064976.0000\n",
            "Epoch [700], val_loss: 38196792.0000\n",
            "Epoch [700], val_loss: 39812680.0000\n",
            "Epoch [700], val_loss: 38381872.0000\n",
            "Epoch [700], val_loss: 38434900.0000\n",
            "Epoch [700], val_loss: 38204880.0000\n",
            "Epoch [700], val_loss: 38326816.0000\n",
            "Epoch [700], val_loss: 38548072.0000\n",
            "Epoch [700], val_loss: 39080776.0000\n",
            "Epoch [700], val_loss: 38533560.0000\n",
            "Epoch [700], val_loss: 38964728.0000\n",
            "Epoch [700], val_loss: 38510004.0000\n",
            "Epoch [800], val_loss: 40299548.0000\n",
            "Epoch [800], val_loss: 39747492.0000\n",
            "Epoch [800], val_loss: 40620688.0000\n",
            "Epoch [800], val_loss: 39636432.0000\n",
            "Epoch [800], val_loss: 43262812.0000\n",
            "Epoch [800], val_loss: 39769740.0000\n",
            "Epoch [800], val_loss: 39390832.0000\n",
            "Epoch [800], val_loss: 40491776.0000\n",
            "Epoch [800], val_loss: 38365336.0000\n",
            "Epoch [800], val_loss: 39136272.0000\n",
            "Epoch [800], val_loss: 38058632.0000\n",
            "Epoch [800], val_loss: 40860476.0000\n",
            "Epoch [800], val_loss: 42489620.0000\n",
            "Epoch [800], val_loss: 38154388.0000\n",
            "Epoch [800], val_loss: 38059248.0000\n",
            "Epoch [800], val_loss: 38272400.0000\n",
            "Epoch [800], val_loss: 38087476.0000\n",
            "Epoch [800], val_loss: 38790284.0000\n",
            "Epoch [800], val_loss: 38297680.0000\n",
            "Epoch [800], val_loss: 39145728.0000\n",
            "Epoch [800], val_loss: 38215708.0000\n",
            "Epoch [800], val_loss: 38266836.0000\n",
            "Epoch [800], val_loss: 38107744.0000\n",
            "Epoch [800], val_loss: 38307700.0000\n",
            "Epoch [800], val_loss: 38572524.0000\n",
            "Epoch [800], val_loss: 38390520.0000\n",
            "Epoch [800], val_loss: 39691668.0000\n",
            "Epoch [800], val_loss: 38313808.0000\n",
            "Epoch [800], val_loss: 38055712.0000\n",
            "Epoch [800], val_loss: 39280848.0000\n",
            "Epoch [800], val_loss: 38485180.0000\n",
            "Epoch [800], val_loss: 38021888.0000\n",
            "Epoch [800], val_loss: 38204884.0000\n",
            "Epoch [800], val_loss: 38075120.0000\n",
            "Epoch [900], val_loss: 37802776.0000\n",
            "Epoch [900], val_loss: 38075988.0000\n",
            "Epoch [900], val_loss: 38307024.0000\n",
            "Epoch [900], val_loss: 37879112.0000\n",
            "Epoch [900], val_loss: 39498104.0000\n",
            "Epoch [900], val_loss: 37833492.0000\n",
            "Epoch [900], val_loss: 38349488.0000\n",
            "Epoch [900], val_loss: 38234312.0000\n",
            "Epoch [900], val_loss: 38522148.0000\n",
            "Epoch [900], val_loss: 38336552.0000\n",
            "Epoch [900], val_loss: 38414240.0000\n",
            "Epoch [900], val_loss: 41247124.0000\n",
            "Epoch [900], val_loss: 41194896.0000\n",
            "Epoch [900], val_loss: 37885896.0000\n",
            "Epoch [900], val_loss: 39193352.0000\n",
            "Epoch [900], val_loss: 40802640.0000\n",
            "Epoch [900], val_loss: 40666332.0000\n",
            "Epoch [900], val_loss: 38096628.0000\n",
            "Epoch [900], val_loss: 38287300.0000\n",
            "Epoch [900], val_loss: 38540580.0000\n",
            "Epoch [900], val_loss: 40490500.0000\n",
            "Epoch [900], val_loss: 38934740.0000\n",
            "Epoch [900], val_loss: 39342704.0000\n",
            "Epoch [900], val_loss: 38818004.0000\n",
            "Epoch [900], val_loss: 37813860.0000\n",
            "Epoch [900], val_loss: 39544540.0000\n",
            "Epoch [900], val_loss: 41012692.0000\n",
            "Epoch [900], val_loss: 39500720.0000\n",
            "Epoch [900], val_loss: 38721032.0000\n",
            "Epoch [900], val_loss: 37822640.0000\n",
            "Epoch [900], val_loss: 37818952.0000\n",
            "Epoch [900], val_loss: 38192016.0000\n",
            "Epoch [900], val_loss: 41560272.0000\n",
            "Epoch [900], val_loss: 37813200.0000\n",
            "Epoch [1000], val_loss: 39263560.0000\n",
            "Epoch [1000], val_loss: 39502908.0000\n",
            "Epoch [1000], val_loss: 39595976.0000\n",
            "Epoch [1000], val_loss: 39389948.0000\n",
            "Epoch [1000], val_loss: 37708712.0000\n",
            "Epoch [1000], val_loss: 38313072.0000\n",
            "Epoch [1000], val_loss: 37679348.0000\n",
            "Epoch [1000], val_loss: 38190492.0000\n",
            "Epoch [1000], val_loss: 37706288.0000\n",
            "Epoch [1000], val_loss: 39594396.0000\n",
            "Epoch [1000], val_loss: 38180772.0000\n",
            "Epoch [1000], val_loss: 38551332.0000\n",
            "Epoch [1000], val_loss: 39002180.0000\n",
            "Epoch [1000], val_loss: 40052372.0000\n",
            "Epoch [1000], val_loss: 39043888.0000\n",
            "Epoch [1000], val_loss: 40374480.0000\n",
            "Epoch [1000], val_loss: 40679088.0000\n",
            "Epoch [1000], val_loss: 38938372.0000\n",
            "Epoch [1000], val_loss: 39813616.0000\n",
            "Epoch [1000], val_loss: 39628992.0000\n",
            "Epoch [1000], val_loss: 37837428.0000\n",
            "Epoch [1000], val_loss: 37900108.0000\n",
            "Epoch [1000], val_loss: 39064020.0000\n",
            "Epoch [1000], val_loss: 38057044.0000\n",
            "Epoch [1000], val_loss: 40110192.0000\n",
            "Epoch [1000], val_loss: 38215080.0000\n",
            "Epoch [1000], val_loss: 37897956.0000\n",
            "Epoch [1000], val_loss: 37802160.0000\n",
            "Epoch [1000], val_loss: 37709504.0000\n",
            "Epoch [1000], val_loss: 37657504.0000\n",
            "Epoch [1000], val_loss: 38200540.0000\n",
            "Epoch [1000], val_loss: 37671592.0000\n",
            "Epoch [1000], val_loss: 39744076.0000\n",
            "Epoch [1000], val_loss: 38555980.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q: What is the final validation loss of your model?"
      ],
      "metadata": {
        "id": "f-7QRiEQ-ugT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss = 38290980.0000"
      ],
      "metadata": {
        "id": "ek7rsBTi_lAU"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make predictions using the trained model"
      ],
      "metadata": {
        "id": "9sHSnkqL_rGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_single(input, target, model):\n",
        "    inputs = input.unsqueeze(0)\n",
        "    predictions = model(inputs)\n",
        "\n",
        "    prediction = predictions[0].detach()\n",
        "    print(\"Input:\", input)\n",
        "    print(\"Target:\", target)\n",
        "    print(\"Prediction:\", prediction)"
      ],
      "metadata": {
        "id": "Xp4EgXwx_vIi"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input, target = val_ds[0]\n",
        "predict_single(input, target, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2Vgn1d9_-Ic",
        "outputId": "3fa2cede-172f-4e0f-a800-0757abc51d16"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([25.0000,  1.0000, 30.5900,  0.0000,  0.0000,  0.0000])\n",
            "Target: tensor([2727.3950])\n",
            "Prediction: tensor([5998.5039])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input, target = val_ds[10]\n",
        "predict_single(input, target, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwdfGlSXIitm",
        "outputId": "b68210ed-762f-41f6-8cfd-12aec8e3c91a"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([22.0000,  1.0000, 52.5800,  1.0000,  1.0000,  2.0000])\n",
            "Target: tensor([44501.3984])\n",
            "Prediction: tensor([31312.2109])\n"
          ]
        }
      ]
    }
  ]
}